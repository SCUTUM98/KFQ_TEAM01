{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from yolov5.models.experimental import attempt_load\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "from convert_data import collect_data, collect_coordinates\n",
    "from class_mapping import yolo_class_mapping, fire_class_mapping, animals_class_mapping, obstacle_class_mapping\n",
    "from detection import category\n",
    "from perform_object import perform_object\n",
    "from yolo_to_server import send_server\n",
    "from create_polygon import check_polylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv version:  4.8.0\n"
     ]
    }
   ],
   "source": [
    "print('opencv version: ', cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Trained Models & Camera setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 21190557 parameters, 0 gradients\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 20879400 parameters, 0 gradients, 48.2 GFLOPs\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 20887482 parameters, 0 gradients, 48.3 GFLOPs\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 20887482 parameters, 0 gradients, 48.3 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "camera_name = 'KFQ StarValley'\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Load trained YOLOv5 model weights\n",
    "yolo_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/yolov5m.pt'\n",
    "fire_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/fire_smoke.pt'\n",
    "animals_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/animals.pt'\n",
    "obstacle_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/obstacle.pt'\n",
    "\n",
    "yolo_model = attempt_load(yolo_weights_path, device=device)\n",
    "fire_model = attempt_load(fire_weights_path, device=device)\n",
    "animals_model = attempt_load(animals_weights_path, device=device)\n",
    "obstacle_model = attempt_load(obstacle_weights_path, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Road Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"300\" viewBox=\"-80.96000000000001 245.04 2077.92 902.9200000000001\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,1393.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"13.8528\" opacity=\"0.6\" d=\"M 1917.0,1071.0 L 1495.0,1071.0 L 1374.0,1067.0 L 0.0,882.0 L -4.0,755.0 L -4.0,363.0 L 139.0,355.0 L 1489.0,322.0 L 1917.0,322.0 L 1918.0,346.0 L 1920.0,508.0 L 1920.0,623.0 L 1918.0,1067.0 L 1917.0,1071.0 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((1917 1071, 1495 1071, 1374 1067, 0 882, -4 755, -4 363, 139 355, ...>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon_coords = []\n",
    "with open('src/polygon_coords.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        x, y = map(int, line.strip().split(','))\n",
    "        polygon_coords.append((x, y))\n",
    "\n",
    "# Polygon 객체 생성\n",
    "polygon = Polygon(polygon_coords)\n",
    "polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-28 14:28:00\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:00        car  tensor(0.80955)  1444  623  1916  1077   \n",
      "\n",
      "   action_detection action_category event_type  \n",
      "0                 0             NaN        NaN  \n",
      "2023-08-28 14:28:03\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:03        car  tensor(0.93385)   612  527  1086   738   \n",
      "1  2023-08-28 14:28:03     person  tensor(0.79034)   934  937  1026  1079   \n",
      "2  2023-08-28 14:28:03     person  tensor(0.77274)  1428  408  1509   574   \n",
      "3  2023-08-28 14:28:03       fire  tensor(0.62521)  1672  665  1916   937   \n",
      "4  2023-08-28 14:28:03       deer  tensor(0.69632)   901  540  1091   737   \n",
      "\n",
      "   action_detection            action_category event_type  \n",
      "0                 0                        NaN        NaN  \n",
      "1                 1            person detected        P01  \n",
      "2                 1            person detected        P01  \n",
      "3                 1              fire detected        F01  \n",
      "4                 1  animal detected(deer/elk)        A02  \n",
      "2023-08-28 14:28:05\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:05        car  tensor(0.93025)   375  670  1082  934   \n",
      "1  2023-08-28 14:28:05       fire  tensor(0.65201)  1671  665  1916  937   \n",
      "2  2023-08-28 14:28:05        cat  tensor(0.70414)   870  839   979  928   \n",
      "\n",
      "   action_detection           action_category event_type  \n",
      "0                 0                       NaN        NaN  \n",
      "1                 1             fire detected        F01  \n",
      "2                 1  animal detected(cat/dog)        A01  \n",
      "2023-08-28 14:28:08\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:08     person  tensor(0.73266)   381  807   474  1072   \n",
      "1  2023-08-28 14:28:08        car  tensor(0.66928)  1009  821  1632  1079   \n",
      "2  2023-08-28 14:28:08       fire  tensor(0.67361)  1671  667  1916   933   \n",
      "\n",
      "   action_detection  action_category event_type  \n",
      "0                 1  person detected        P01  \n",
      "1                 0              NaN        NaN  \n",
      "2                 1    fire detected        F01  \n",
      "2023-08-28 14:28:11\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "tire on vehicle: 1\n",
      "on the vehicle\n",
      "tire on vehicle: 0\n",
      "tire on vehicle: 0\n",
      "tire on vehicle: 0\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:11        car  tensor(0.89376)     1  630   215   934   \n",
      "1  2023-08-28 14:28:11     person  tensor(0.71815)   363  806   460  1067   \n",
      "2  2023-08-28 14:28:11       fire  tensor(0.64834)  1669  668  1915   933   \n",
      "3  2023-08-28 14:28:11       tire  tensor(0.67282)     1  844    67   936   \n",
      "\n",
      "   action_detection          action_category event_type  \n",
      "0                 0                      NaN        NaN  \n",
      "1                 1          person detected        P01  \n",
      "2                 1            fire detected        F01  \n",
      "3                 1  obstacle detected(tire)        S04  \n",
      "2023-08-28 14:28:14\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:14      truck  tensor(0.79009)  1063  450  1607  683   \n",
      "1  2023-08-28 14:28:14     person  tensor(0.66008)   368  723   446  936   \n",
      "2  2023-08-28 14:28:14       fire  tensor(0.64818)  1668  669  1917  938   \n",
      "\n",
      "   action_detection  action_category event_type  \n",
      "0                 0              NaN        NaN  \n",
      "1                 1  person detected        P01  \n",
      "2                 1    fire detected        F01  \n",
      "2023-08-28 14:28:16\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:16       fire  tensor(0.67874)  1666  664  1916   936   \n",
      "1  2023-08-28 14:28:16   car fire  tensor(0.42868)     7  704   625  1066   \n",
      "\n",
      "   action_detection    action_category event_type  \n",
      "0                 1      fire detected        F01  \n",
      "1                 1  car fire detected        F03  \n",
      "2023-08-28 14:28:19\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:19     person  tensor(0.70485)   426  533   481  681   \n",
      "1  2023-08-28 14:28:19        car  tensor(0.68080)  1482  770  1774  984   \n",
      "2  2023-08-28 14:28:19       fire  tensor(0.60327)  1658  665  1924  884   \n",
      "\n",
      "   action_detection  action_category event_type  \n",
      "0                 1  person detected        P01  \n",
      "1                 0              NaN        NaN  \n",
      "2                 1    fire detected        F01  \n",
      "2023-08-28 14:28:22\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:22       fire  tensor(0.69262)  1667  665  1916  931   \n",
      "\n",
      "   action_detection action_category event_type  \n",
      "0                 1   fire detected        F01  \n",
      "2023-08-28 14:28:24\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:24     person  tensor(0.88341)  1452  703  1553  944   \n",
      "1  2023-08-28 14:28:24       fire  tensor(0.67442)  1665  666  1917  935   \n",
      "\n",
      "   action_detection  action_category event_type  \n",
      "0                 1  person detected        P01  \n",
      "1                 1    fire detected        F01  \n",
      "2023-08-28 14:28:27\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:27     person  tensor(0.88876)  1182  834  1283  1079   \n",
      "1  2023-08-28 14:28:27       fire  tensor(0.67471)  1671  665  1916   935   \n",
      "2  2023-08-28 14:28:27       deer  tensor(0.82548)  1184  833  1294  1079   \n",
      "\n",
      "   action_detection            action_category event_type  \n",
      "0                 1            person detected        P01  \n",
      "1                 1              fire detected        F01  \n",
      "2                 1  animal detected(deer/elk)        A02  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(camera_name, frame)\n\u001b[1;32m     42\u001b[0m     \u001b[39m#send_server(results_df, camera_name, frame)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m) \u001b[39m# 2초 간격으로 사진 캡쳐\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Release the webcam and close windows\u001b[39;00m\n\u001b[1;32m     47\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read frame from the webcam\n",
    "    captured_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") # 상황 발생 시간 기록\n",
    "    print(captured_time)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit the loop\n",
    "        break\n",
    "    \n",
    "    # reset dataframe\n",
    "    columns = ['Time', 'Class_Name', 'Confidence', 'X1', 'Y1', 'X2', 'Y2', 'action_detection', 'action_category', 'event_type']\n",
    "    results_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Preprocess the frame\n",
    "    image = Image.fromarray(frame)\n",
    "    image = image.resize((640, 640))  # Resize the image to the model's input size\n",
    "    image_tensor = torch.from_numpy(np.array(image)).float().permute(2, 0, 1) / 255.0\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # Perform object detection\n",
    "    results = perform_object(image_tensor, 0.65, yolo_model)\n",
    "    results_df = collect_data(results, frame, yolo_class_mapping, results_df, captured_time)\n",
    "    #print(results_df)\n",
    "    \n",
    "    results = perform_object(image_tensor, 0.4, fire_model)\n",
    "    results_df = collect_data(results, frame, fire_class_mapping, results_df, captured_time)\n",
    "    \n",
    "    results = perform_object(image_tensor, 0.65, animals_model)\n",
    "    results_df = collect_data(results, frame, animals_class_mapping, results_df, captured_time)\n",
    "    \n",
    "    results = perform_object(image_tensor, 0.4, obstacle_model)\n",
    "    results_df = collect_data(results, frame, obstacle_class_mapping, results_df, captured_time)\n",
    "    \n",
    "    results_df = category(results_df, polygon)\n",
    "    print(results_df)\n",
    "\n",
    "    # Display the frame with bounding boxes and labels\n",
    "    cv2.imshow(camera_name, frame)\n",
    "    \n",
    "    #send_server(results_df, camera_name, frame)\n",
    "    \n",
    "    time.sleep(2) # 2초 간격으로 사진 캡쳐\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
