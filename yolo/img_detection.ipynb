{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from yolov5.models.experimental import attempt_load\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "from convert_data import collect_data, collect_coordinates\n",
    "from class_mapping import yolo_class_mapping, fire_class_mapping, animals_class_mapping, obstacle_class_mapping\n",
    "from detection import category\n",
    "from perform_object import perform_object\n",
    "from yolo_to_server import send_server\n",
    "from create_polygon import check_polylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv version:  4.8.0\n"
     ]
    }
   ],
   "source": [
    "print('opencv version: ', cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Trained Models & Camera setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 21190557 parameters, 0 gradients\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 20879400 parameters, 0 gradients, 48.2 GFLOPs\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 20887482 parameters, 0 gradients, 48.3 GFLOPs\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 20887482 parameters, 0 gradients, 48.3 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "camera_name = 'KFQ StarValley'\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Load trained YOLOv5 model weights\n",
    "yolo_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/yolov5m.pt'\n",
    "fire_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/fire_smoke.pt'\n",
    "animals_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/animals.pt'\n",
    "obstacle_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/obstacle.pt'\n",
    "\n",
    "yolo_model = attempt_load(yolo_weights_path, device=device)\n",
    "fire_model = attempt_load(fire_weights_path, device=device)\n",
    "animals_model = attempt_load(animals_weights_path, device=device)\n",
    "obstacle_model = attempt_load(obstacle_weights_path, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save coordinates for road boundary detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X1   Y1    X2   Y2 Class_Name\n",
      "0    1491  348  1917  684        bus\n",
      "1    1383  352  1917  693        bus\n",
      "2    1288  352  1918  708        bus\n",
      "3    1197  355  1917  709        bus\n",
      "4    1118  357  1913  710        bus\n",
      "..    ...  ...   ...  ...        ...\n",
      "106     1  367   698  717        bus\n",
      "107     1  367   603  716        bus\n",
      "108     0  371   496  723        bus\n",
      "109     1  361   480  727        bus\n",
      "110     0  380   277  698        bus\n",
      "\n",
      "[111 rows x 5 columns]\n",
      "coodrinates count: 111\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"300\" viewBox=\"-76.92 271.08 2076.84 872.8400000000001\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,1415.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"13.845600000000001\" opacity=\"0.6\" d=\"M 0.0,747.0 L 0.0,371.0 L 1.0,361.0 L 1491.0,348.0 L 1918.0,348.0 L 1919.0,356.0 L 1923.0,480.0 L 1923.0,970.0 L 1918.0,1064.0 L 1917.0,1067.0 L 1320.0,1067.0 L 1.0,1031.0 L 0.0,747.0 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((0 747, 0 371, 1 361, 1491 348, 1918 348, 1919 356, 1923 480, 1923...>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "columns = ['X1', 'Y1', 'X2', 'Y2', 'Class_Name']\n",
    "road_coordinates = pd.DataFrame(columns=columns)\n",
    "sidewalk_coordinates = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(400):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image = Image.fromarray(frame)\n",
    "    image = image.resize((640,640))\n",
    "    image_tensor = torch.from_numpy(np.array(image)).float().permute(2, 0, 1) / 255.0\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    results = perform_object(image_tensor, 0.65, yolo_model)\n",
    "    road_coordinates, sidewalk_coordinates = collect_coordinates(results, frame, yolo_class_mapping, road_coordinates, sidewalk_coordinates)\n",
    "\n",
    "cap.release()\n",
    "print(road_coordinates)\n",
    "print(f'coodrinates count: {len(road_coordinates)}')\n",
    "\n",
    "# Create road boundary polygon using road coordinates data\n",
    "polygon = check_polylist(road_coordinates)\n",
    "polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-28 14:28:00\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:00        car  tensor(0.80955)  1444  623  1916  1077   \n",
      "\n",
      "   action_detection action_category event_type  \n",
      "0                 0             NaN        NaN  \n",
      "2023-08-28 14:28:03\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:03        car  tensor(0.93385)   612  527  1086   738   \n",
      "1  2023-08-28 14:28:03     person  tensor(0.79034)   934  937  1026  1079   \n",
      "2  2023-08-28 14:28:03     person  tensor(0.77274)  1428  408  1509   574   \n",
      "3  2023-08-28 14:28:03       fire  tensor(0.62521)  1672  665  1916   937   \n",
      "4  2023-08-28 14:28:03       deer  tensor(0.69632)   901  540  1091   737   \n",
      "\n",
      "   action_detection            action_category event_type  \n",
      "0                 0                        NaN        NaN  \n",
      "1                 1            person detected        P01  \n",
      "2                 1            person detected        P01  \n",
      "3                 1              fire detected        F01  \n",
      "4                 1  animal detected(deer/elk)        A02  \n",
      "2023-08-28 14:28:05\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:05        car  tensor(0.93025)   375  670  1082  934   \n",
      "1  2023-08-28 14:28:05       fire  tensor(0.65201)  1671  665  1916  937   \n",
      "2  2023-08-28 14:28:05        cat  tensor(0.70414)   870  839   979  928   \n",
      "\n",
      "   action_detection           action_category event_type  \n",
      "0                 0                       NaN        NaN  \n",
      "1                 1             fire detected        F01  \n",
      "2                 1  animal detected(cat/dog)        A01  \n",
      "2023-08-28 14:28:08\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:08     person  tensor(0.73266)   381  807   474  1072   \n",
      "1  2023-08-28 14:28:08        car  tensor(0.66928)  1009  821  1632  1079   \n",
      "2  2023-08-28 14:28:08       fire  tensor(0.67361)  1671  667  1916   933   \n",
      "\n",
      "   action_detection  action_category event_type  \n",
      "0                 1  person detected        P01  \n",
      "1                 0              NaN        NaN  \n",
      "2                 1    fire detected        F01  \n",
      "2023-08-28 14:28:11\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "tire on vehicle: 1\n",
      "on the vehicle\n",
      "tire on vehicle: 0\n",
      "tire on vehicle: 0\n",
      "tire on vehicle: 0\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:11        car  tensor(0.89376)     1  630   215   934   \n",
      "1  2023-08-28 14:28:11     person  tensor(0.71815)   363  806   460  1067   \n",
      "2  2023-08-28 14:28:11       fire  tensor(0.64834)  1669  668  1915   933   \n",
      "3  2023-08-28 14:28:11       tire  tensor(0.67282)     1  844    67   936   \n",
      "\n",
      "   action_detection          action_category event_type  \n",
      "0                 0                      NaN        NaN  \n",
      "1                 1          person detected        P01  \n",
      "2                 1            fire detected        F01  \n",
      "3                 1  obstacle detected(tire)        S04  \n",
      "2023-08-28 14:28:14\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:14      truck  tensor(0.79009)  1063  450  1607  683   \n",
      "1  2023-08-28 14:28:14     person  tensor(0.66008)   368  723   446  936   \n",
      "2  2023-08-28 14:28:14       fire  tensor(0.64818)  1668  669  1917  938   \n",
      "\n",
      "   action_detection  action_category event_type  \n",
      "0                 0              NaN        NaN  \n",
      "1                 1  person detected        P01  \n",
      "2                 1    fire detected        F01  \n",
      "2023-08-28 14:28:16\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:16       fire  tensor(0.67874)  1666  664  1916   936   \n",
      "1  2023-08-28 14:28:16   car fire  tensor(0.42868)     7  704   625  1066   \n",
      "\n",
      "   action_detection    action_category event_type  \n",
      "0                 1      fire detected        F01  \n",
      "1                 1  car fire detected        F03  \n",
      "2023-08-28 14:28:19\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:19     person  tensor(0.70485)   426  533   481  681   \n",
      "1  2023-08-28 14:28:19        car  tensor(0.68080)  1482  770  1774  984   \n",
      "2  2023-08-28 14:28:19       fire  tensor(0.60327)  1658  665  1924  884   \n",
      "\n",
      "   action_detection  action_category event_type  \n",
      "0                 1  person detected        P01  \n",
      "1                 0              NaN        NaN  \n",
      "2                 1    fire detected        F01  \n",
      "2023-08-28 14:28:22\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:22       fire  tensor(0.69262)  1667  665  1916  931   \n",
      "\n",
      "   action_detection action_category event_type  \n",
      "0                 1   fire detected        F01  \n",
      "2023-08-28 14:28:24\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2   Y2  \\\n",
      "0  2023-08-28 14:28:24     person  tensor(0.88341)  1452  703  1553  944   \n",
      "1  2023-08-28 14:28:24       fire  tensor(0.67442)  1665  666  1917  935   \n",
      "\n",
      "   action_detection  action_category event_type  \n",
      "0                 1  person detected        P01  \n",
      "1                 1    fire detected        F01  \n",
      "2023-08-28 14:28:27\n",
      "state: 1\n",
      "state: 1\n",
      "state: 1\n",
      "                  Time Class_Name       Confidence    X1   Y1    X2    Y2  \\\n",
      "0  2023-08-28 14:28:27     person  tensor(0.88876)  1182  834  1283  1079   \n",
      "1  2023-08-28 14:28:27       fire  tensor(0.67471)  1671  665  1916   935   \n",
      "2  2023-08-28 14:28:27       deer  tensor(0.82548)  1184  833  1294  1079   \n",
      "\n",
      "   action_detection            action_category event_type  \n",
      "0                 1            person detected        P01  \n",
      "1                 1              fire detected        F01  \n",
      "2                 1  animal detected(deer/elk)        A02  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(camera_name, frame)\n\u001b[1;32m     42\u001b[0m     \u001b[39m#send_server(results_df, camera_name, frame)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m) \u001b[39m# 2초 간격으로 사진 캡쳐\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Release the webcam and close windows\u001b[39;00m\n\u001b[1;32m     47\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read frame from the webcam\n",
    "    captured_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") # 상황 발생 시간 기록\n",
    "    print(captured_time)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit the loop\n",
    "        break\n",
    "    \n",
    "    # reset dataframe\n",
    "    columns = ['Time', 'Class_Name', 'Confidence', 'X1', 'Y1', 'X2', 'Y2', 'action_detection', 'action_category', 'event_type']\n",
    "    results_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Preprocess the frame\n",
    "    image = Image.fromarray(frame)\n",
    "    image = image.resize((640, 640))  # Resize the image to the model's input size\n",
    "    image_tensor = torch.from_numpy(np.array(image)).float().permute(2, 0, 1) / 255.0\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # Perform object detection\n",
    "    results = perform_object(image_tensor, 0.65, yolo_model)\n",
    "    results_df = collect_data(results, frame, yolo_class_mapping, results_df, captured_time)\n",
    "    #print(results_df)\n",
    "    \n",
    "    results = perform_object(image_tensor, 0.4, fire_model)\n",
    "    results_df = collect_data(results, frame, fire_class_mapping, results_df, captured_time)\n",
    "    \n",
    "    results = perform_object(image_tensor, 0.65, animals_model)\n",
    "    results_df = collect_data(results, frame, animals_class_mapping, results_df, captured_time)\n",
    "    \n",
    "    results = perform_object(image_tensor, 0.4, obstacle_model)\n",
    "    results_df = collect_data(results, frame, obstacle_class_mapping, results_df, captured_time)\n",
    "    \n",
    "    results_df = category(results_df, polygon)\n",
    "    print(results_df)\n",
    "\n",
    "    # Display the frame with bounding boxes and labels\n",
    "    cv2.imshow(camera_name, frame)\n",
    "    \n",
    "    #send_server(results_df, camera_name, frame)\n",
    "    \n",
    "    time.sleep(2) # 2초 간격으로 사진 캡쳐\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
