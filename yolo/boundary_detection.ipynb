{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from yolov5.models.experimental import attempt_load\n",
    "from class_mapping import yolo_class_mapping\n",
    "from perform_object import perform_object\n",
    "from convert_data import collect_coordinates\n",
    "from create_polygon import check_polylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check opencv version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv version:  4.8.0\n"
     ]
    }
   ],
   "source": [
    "print('opencv version: ', cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 21190557 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# Load trained YOLOv5 model weights\n",
    "yolo_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/yolov5m.pt'\n",
    "\n",
    "yolo_model = attempt_load(yolo_weights_path, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create polygon using road boundary coordinates data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X1   Y1    X2   Y2 Class_Name\n",
      "0     904  157  1236  339        car\n",
      "1     411  389   974  752        car\n",
      "2    1075  401  1699  701        car\n",
      "3       0  301   190  593        car\n",
      "4     725   97  1025  265        car\n",
      "..    ...  ...   ...  ...        ...\n",
      "686   843  608  1482  947        car\n",
      "687   425  478   985  771        car\n",
      "688   118  380   634  644        car\n",
      "689     0  297   324  528        car\n",
      "690     0  266    50  411        car\n",
      "\n",
      "[691 rows x 5 columns]\n",
      "coodrinates count: 691\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"300\" viewBox=\"-79.0 -78.0 2079.0 1240.0\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,1084.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"13.86\" opacity=\"0.6\" d=\"M 1918.0,0.0 L 1923.0,360.0 L 1923.0,644.0 L 1920.0,1079.0 L 1919.0,1080.0 L 953.0,1085.0 L 273.0,1085.0 L 0.0,1081.0 L -2.0,408.0 L -2.0,134.0 L 0.0,0.0 L 209.0,-1.0 L 593.0,-1.0 L 1918.0,0.0 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((1918 0, 1923 360, 1923 644, 1920 1079, 1919 1080, 953 1085, 273 1...>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "columns = ['X1', 'Y1', 'X2', 'Y2', 'Class_Name']\n",
    "road_coordinates = pd.DataFrame(columns=columns)\n",
    "sidewalk_coordinates = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(400):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image = Image.fromarray(frame)\n",
    "    image = image.resize((640,640))\n",
    "    image_tensor = torch.from_numpy(np.array(image)).float().permute(2, 0, 1) / 255.0\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    results = perform_object(image_tensor, 0.65, yolo_model)\n",
    "    road_coordinates, sidewalk_coordinates = collect_coordinates(results, frame, yolo_class_mapping, road_coordinates, sidewalk_coordinates)\n",
    "\n",
    "cap.release()\n",
    "print(road_coordinates)\n",
    "print(f'coodrinates count: {len(road_coordinates)}')\n",
    "\n",
    "# Create road boundary polygon using road coordinates data\n",
    "polygon = check_polylist(road_coordinates)\n",
    "polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
