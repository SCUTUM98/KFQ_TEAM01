{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from yolov5.models.experimental import attempt_load\n",
    "from class_mapping import yolo_class_mapping\n",
    "from perform_object import perform_object\n",
    "from convert_data import collect_coordinates\n",
    "from create_polygon import check_polylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check opencv version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv version:  4.8.0\n"
     ]
    }
   ],
   "source": [
    "print('opencv version: ', cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5m summary: 369 layers, 21190557 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# Load trained YOLOv5 model weights\n",
    "yolo_weights_path = '/Users/bongeungu/Desktop/kfq/KFQ_TEAM01/yolo/models/yolov5m.pt'\n",
    "\n",
    "yolo_model = attempt_load(yolo_weights_path, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create polygon using road boundary coordinates data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X1   Y1    X2   Y2 Class_Name\n",
      "0    1784  645  1919  740        car\n",
      "1    1677  604  1919  754        car\n",
      "2    1562  613  1916  783        car\n",
      "3    1436  612  1891  791        car\n",
      "4    1307  614  1748  797        car\n",
      "..    ...  ...   ...  ...        ...\n",
      "100   554  701  1156  934        car\n",
      "101   475  698  1076  923        car\n",
      "102   411  690   994  913        car\n",
      "103   313  682   912  905        car\n",
      "104   235  678   832  898        car\n",
      "\n",
      "[105 rows x 5 columns]\n",
      "coodrinates count: 105\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"300\" viewBox=\"-76.76 495.24 2072.52 660.52\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,1651.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"13.8168\" opacity=\"0.6\" d=\"M 1919.0,784.0 L 1918.0,1079.0 L 1237.0,1079.0 L 1174.0,1078.0 L 235.0,898.0 L 1.0,848.0 L 0.0,842.0 L 0.0,615.0 L 2.0,613.0 L 328.0,604.0 L 1311.0,579.0 L 1670.0,572.0 L 1919.0,572.0 L 1919.0,784.0 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((1919 784, 1918 1079, 1237 1079, 1174 1078, 235 898, 1 848, 0 842,...>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "columns = ['X1', 'Y1', 'X2', 'Y2', 'Class_Name']\n",
    "road_coordinates = pd.DataFrame(columns=columns)\n",
    "sidewalk_coordinates = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(400):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image = Image.fromarray(frame)\n",
    "    image = image.resize((640,640))\n",
    "    image_tensor = torch.from_numpy(np.array(image)).float().permute(2, 0, 1) / 255.0\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    results = perform_object(image_tensor, 0.65, yolo_model)\n",
    "    road_coordinates, sidewalk_coordinates = collect_coordinates(results, frame, yolo_class_mapping, road_coordinates, sidewalk_coordinates)\n",
    "\n",
    "cap.release()\n",
    "print(road_coordinates)\n",
    "print(f'coodrinates count: {len(road_coordinates)}')\n",
    "\n",
    "# Create road boundary polygon using road coordinates data\n",
    "polygon = check_polylist(road_coordinates)\n",
    "polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
